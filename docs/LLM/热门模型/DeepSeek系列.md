---
article: false
title: DeepSeekç³»åˆ—
order: 2
---

## é—®é¢˜å’Œç»“è®º

1. MOE èƒ½å¦åšçŸ¥è¯†è’¸é¦ï¼Ÿ <span style="color:blue;">**å¯ä»¥**</span>
2. MOE ç›¸æ¯” Dense çš„ä¼˜åŠ¿ï¼Ÿ <span style="color:blue;">**èŠ‚çº¦è®¡ç®—æˆæœ¬**</span>
3. ä»€ä¹ˆç»“æ„èƒ½ç”¨ MOEï¼Ÿ  <span style="color:blue;">**ä»»ä½• FFN â†’ å¤šä»»åŠ¡é—®é¢˜**</span>
4. åœ¨å·²çŸ¥ MOE æœ‰è´Ÿè½½ä¸å‡è¡¡é—®é¢˜çš„å‰æä¸‹ï¼Œä¸ºå•¥ç›®å‰å¤§æ¨¡å‹éƒ½å¼€å§‹æŠ›å¼ƒä¼ ç»Ÿ Transformer æ¶æ„ï¼Œè½¬æŠ• MOEï¼Ÿ <span style="color:blue;">**ä¾¿å®œ**</span>
5. ä¸ªäººåŸæ¥çš„ç†è§£ï¼šMOE åªèƒ½èŠ‚çº¦è®­ç»ƒå’Œæ¨ç†çš„è®¡ç®—é‡ï¼Œä¸èƒ½èŠ‚çº¦å­˜å‚¨é‡ï¼›æ¨¡å‹è’¸é¦å¯ä»¥èŠ‚çº¦è®¡ç®—é‡ï¼Œä¹Ÿå¯ä»¥èŠ‚çº¦å­˜å‚¨é‡ï¼Œæ˜¯å¦æ­£ç¡®ï¼Ÿ <span style="color:blue;">**æ­£ç¡®**</span>

> **ğŸ’¡é”™è¯¯è§‚ç‚¹**ï¼š
>
> 1. MOE æ˜¯ä¸ºäº†å‡å°ç½‘ç»œç»“æ„ï¼Ÿ âŒ ç›¸åï¼ŒMOEçš„åˆè¡·æ˜¯ä¸ºäº†åœ¨ä¿è¯è¾ƒä½è®¡ç®—é‡çš„åŒæ—¶ï¼Œå¢åŠ æ¨¡å‹å‚æ•°ï¼Œä½¿æ¨¡å‹æ›´å¼º
> 2. MOE æ˜¯ä¸ºäº†å°†æ·±å±‚ç½‘ç»œå˜ä¸ºæµ…å±‚ç½‘ç»œï¼Ÿ âŒ å°†ä¸­é—´å±‚å‚æ•°æ•°é‡ä» Nï¼Œé™ä½ä¸º N/Eï¼Œåˆ†æ•£åˆ°Eä¸ªä¸“å®¶ä¸Šï¼Œå¯èƒ½å¯ä»¥å°†ç½‘ç»œå˜æµ…ï¼Œä½†è¿™ä¸æ˜¯ä¸»è¦ç›®çš„
> åŸæ¥ä»¥ä¸ºMOEæ˜¯é’ˆå¯¹æ·±å±‚ç½‘ç»œåšçš„ä¼˜åŒ–ï¼Œå°†æ·±å±‚ç½‘ç»œå˜ä¸ºæµ…å±‚ç½‘ç»œï¼Œä½†æ˜¯å®é™…æ˜¯


### DeepSeek ç ”ç©¶è„‰ç»œ

ğŸ’¡ **ä»ç¨ å¯†æ¨¡å‹åˆ°æ··åˆä¸“å®¶ï¼Œå†åˆ°æ¨ç†æ–¹å‘**

å›é¡¾ DeepSeek è¿‡å»ä¸€å¹´å¤šå‘è¡¨çš„æ ¸å¿ƒè®ºæ–‡ï¼Œæˆ‘ä»¬å¤§è‡´èƒ½å°†å…¶ç ”ç©¶åˆ†ä¸ºä¸¤æ¡ä¸»è¦è„‰ç»œï¼šã€€

- **åŸºåº§æ¨¡å‹ï¼ˆFoundation Modelsï¼‰**ï¼šä»æœ€æ—©çš„ Denseï¼ˆç¨ å¯†ï¼‰ç»“æ„ä¸€è·¯æ¼”è¿›åˆ° MOEï¼ˆæ··åˆä¸“å®¶ï¼‰æ¨¡å¼ï¼Œå¹¶åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ä¸æ–­å‘æ˜å’Œé‡‡ç”¨æ–°çš„é«˜æ•ˆè®­ç»ƒç®—æ³•ã€‚
- **æ¨ç†èƒ½åŠ›ï¼ˆReasoningï¼‰**ï¼šåŒ…æ‹¬è§£æ•°å­¦é¢˜ã€ä»£ç ç”Ÿæˆã€é€»è¾‘é—®ç­”ä¹ƒè‡³å®šç†è¯æ˜ç­‰ï¼Œæ›´å¼ºè°ƒå¤§æ¨¡å‹çš„"æ€è€ƒæ·±åº¦"ï¼Œå¹¶åœ¨å¦‚ä½•è¿›è¡Œå¼ºåŒ–å­¦ä¹ æ–¹é¢è¿›è¡Œäº†è¿ç»­å¤šæ¬¡åˆ›æ–°ã€‚


## MOE åŸºæœ¬åŸç†

MOE å…¨ç§°æ˜¯ Mixture of Expertsï¼Œä¹Ÿå°±æ˜¯æ··åˆä¸“å®¶æ¨¡å‹ã€‚

æ¨¡å‹è§„æ¨¡æ˜¯æå‡æ¨¡å‹æ€§èƒ½çš„å…³é”®å› ç´ ä¹‹ä¸€ã€‚åœ¨æœ‰é™çš„è®¡ç®—èµ„æºé¢„ç®—ä¸‹ï¼Œç”¨æ›´å°‘çš„è®­ç»ƒæ­¥æ•°è®­ç»ƒä¸€ä¸ªæ›´å¤§çš„æ¨¡å‹ï¼Œå¾€å¾€æ¯”ç”¨æ›´å¤šçš„æ­¥æ•°è®­ç»ƒä¸€ä¸ªè¾ƒå°çš„æ¨¡å‹æ•ˆæœæ›´ä½³ã€‚

è¿‘æœŸå‘å¸ƒçš„å¤§æ¨¡å‹å¼€å§‹å¹¿æ³›è½¬å‘MOEæ¶æ„ï¼š

![image-20250427011529235](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250427011529235.webp)

### æœ€æœ€æœ€åŸå§‹ç‰ˆ

![image-20250427012214472](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250427012214472.webp)

#### ç»„æˆ

1. **ç¨€ç– MOE å±‚**ï¼šn ä¸ªä¸“å®¶ FFN
2. **è·¯ç”±**ï¼štoken åˆ° top-K ä¸ªä¸“å®¶

è®¡ç®—æ–¹å¼å¦‚ä¸‹å›¾

![MOEè®¡ç®—](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250427013428021.webp)

#### FFN å¯¹æ¯”

- **Vs Transformer**

![Transformerå¯¹æ¯”](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/cb648375-82d9-4f82-9fbe-d2215310d62c.webp)

| ![FFn](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/f61ccc9d-e249-4399-b5d5-fe4047576725.webp) | ![MOEå…¬å¼](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/c7c02a38-3840-4f5e-ad60-06dc6ece64b2.webp) |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
|                             FFN                              |                             MOE                              |

- **ä¸€èˆ¬çš„ gating network çš„è®¡ç®—ï¼Œä¾¿äºå’Œ deepseek åšå¯¹æ¯”**

![0095a6a0-a489-42cc-86d5-6674fa92d8df](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/0095a6a0-a489-42cc-86d5-6674fa92d8df.webp)

#### ç‰¹ç‚¹

- ç›¸æ¯” dense æ¨¡å‹ï¼Œ**é¢„è®­ç»ƒé€Ÿåº¦æ›´å¿«**
- ç›¸æ¯”åŒå‚æ•°é‡æ¨¡å‹ï¼Œ**æ¨ç†é€Ÿåº¦æ›´å¿«**
- ä½†æ˜¯éœ€è¦é«˜ VRAMï¼Œå› ä¸ºæ‰€æœ‰ä¸“å®¶éƒ½åŠ è½½åœ¨å†…å­˜ä¸­
- åœ¨ **å¾®è°ƒæ–¹é¢å­˜åœ¨è¯¸å¤šæŒ‘æˆ˜**

> ä¸€ä¸ªæœ€ç›´è§‚çš„æ•°æ®ï¼š
>
> åœ¨ DeepSeek å®˜ç½‘ä¸Šçœ‹åˆ°ï¼ŒDeepSeek-V3ã€V2.5 ç‰ˆæœ¬éƒ½ç”¨äº† MoE æ¶æ„ã€‚ä½†åƒ Qwenã€LLama æ¨¡å‹ï¼Œç”¨çš„å´æ˜¯ Dense æ¶æ„ï¼Œä¹Ÿå°±æ˜¯ä¼ ç»Ÿçš„ Transformer æ¶æ„ã€‚è¿™ä¸¤ç§æ¶æ„æœ‰ä¸ªå¾ˆæ˜æ˜¾çš„åŒºåˆ«ã€‚DeepSeek-V3 ç‰ˆæœ¬æ€»å‚æ•°é‡é«˜è¾¾ 6710 äº¿ï¼Œå¯æ¯æ¬¡è®¡ç®—æ¿€æ´»çš„å‚æ•°é‡ï¼Œä¹Ÿå°±æ˜¯çœŸæ­£å‚ä¸åˆ°è®¡ç®—é‡Œçš„å‚æ•°ï¼Œåªæœ‰ 370 äº¿ï¼Œæ˜¯æ€»å‚æ•°é‡çš„  <span style="color:blue;">**5.5%**</span>ã€‚ä½† Qwen å’Œ LLama æ¨¡å‹å°±ä¸ä¸€æ ·äº†ï¼Œå®ƒä»¬æ¯æ¬¡è®¡ç®—æ¿€æ´»çš„å‚æ•°é‡ï¼Œå°±æ˜¯æ•´ä¸ªæ¨¡å‹çš„å‚æ•°é‡ï¼Œæ²¡æœ‰ â€œæ‰“æŠ˜â€ã€‚

### Switch Transformer

![18fc4416-2296-4eb5-910e-a0b5b0984782](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/18fc4416-2296-4eb5-910e-a0b5b0984782.webp)

### æœ€å¤§é—®é¢˜-è´Ÿè½½å‡è¡¡

> å¯èƒ½æœ‰çš„ä¸“å®¶æ›´æ–°è®¡ç®—çš„éå¸¸é¢‘ç¹ï¼Œæœ‰çš„ä¸“å®¶æ ¹æœ¬ä¸åŠ¨ï¼›éšç€è®­ç»ƒçš„è¿›è¡Œï¼Œä¼šå‘ç°æ¨¡å‹ä¼šå€¾å‘ä¸æ›´æ–°å¿«çš„ä¸“å®¶

- é—¨æ§ç½‘ç»œå¾€å¾€å€¾å‘äºä¸»è¦æ¿€æ´»ç›¸åŒçš„å‡ ä¸ªä¸“å®¶ã€‚å—æ¬¢è¿çš„ä¸“å®¶è®­ç»ƒå¾—æ›´å¿«ï¼Œå› æ­¤æ›´å®¹æ˜“è¢«é€‰æ‹©
- å¼•å…¥äº†ä¸€ä¸ª<span style="color:blue;">**è¾…åŠ©æŸå¤±Aux Loss**</span>ï¼Œé¼“åŠ±æ‰€æœ‰ä¸“å®¶ç›¸åŒçš„é‡è¦æ€§ï¼Œå¹³è¡¡è®¡ç®—é‡ï¼Œä½¿å¾—ä¸åŒä¸“å®¶å­¦ä¹ ä¸åŒçš„çŸ¥è¯†
- Aux Lossç¡®ä¿æ‰€æœ‰ä¸“å®¶æ¥æ”¶åˆ°å¤§è‡´ç›¸ç­‰æ•°é‡çš„è®­ç»ƒæ ·æœ¬ï¼Œä»è€Œå¹³è¡¡ä¸“å®¶é—´é€‰æ‹©

**Aux lossè®¡ç®—**

![image-20250427015343377](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250427015343377.webp)

æ›¿æ¢ä¸€ä¸ª$\frac{c_e}{s}$ä¸º$m_e$ï¼Œå¼•å…¥å¯å­¦ä¹ å‚æ•°ï¼Œå¾—åˆ°ï¼š

![image-20250427015637422](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250427015637422.webp)

## DeepSeek MOE(2024.01)

DeepSeek-V1 åº”è¯¥æ˜¯ 2023 å¹´ 12 æœˆçš„ DeepSeek LLM Base å’Œ Chat æ¨¡å‹ï¼Œæ˜¯ç¨ å¯†æ¨¡å‹ã€‚

DeepSeek-V2 åŠå…¶ä¹‹åçš„æ¨¡å‹ç”¨çš„éƒ½æ˜¯ MoE äº†ã€‚

[DeepSeek MOE åŸæ–‡](https://arxiv.org/pdf/2401.06066)

### èƒŒæ™¯

- LLM ä¸­ï¼Œ<span style="color:blue;">**æ‰©å±•æ¨¡å‹å‚æ•°æ—¶èŠ‚çº¦æˆæœ¬**</span>ï¼Œæ•…ä½¿ç”¨ MoEã€‚MOEæ¶æ„è¿˜æ˜¯å¾ˆæœ‰å‰é€”çš„ï¼Œä½†æ˜¯ä¹‹å‰çš„MOEæ¶æ„ä¸èƒ½å¾ˆå¥½çš„ç¨³å®šçš„æ”¶æ•›äº†ï¼Œæ¯ä¸ªä¸“å®¶è·å–çš„çŸ¥è¯†å·®å¼‚åŒ–ä¸æ˜æ˜¾ã€‚
- Deepseek MOE å°±æ˜¯ä¸ºäº†é€šè¿‡æ›´åŠ é«˜æ•ˆçš„æœºåˆ¶æ¥ç¡®ä¿ä¸“å®¶ä¹‹é—´çš„ä»»åŠ¡åˆ†é…å…·æœ‰æ›´é«˜çš„<span style="color:blue;">**ä¸“é—¨åŒ–**</span>ã€‚
- æ— æ³•ç¡®ä¿ä¸“å®¶çš„ä¸“é—¨åŒ–ï¼šè¿™ç§é‡å ä¼šå¯¼è‡´ä¸“å®¶æ²¡æœ‰è·å¾—è¶³å¤Ÿçš„ç‹¬ç‰¹çŸ¥è¯†ï¼Œä¹Ÿä½¿å¾—ä¸“å®¶ä¹‹é—´çš„å·®å¼‚åŒ–ä¸æ˜æ˜¾ï¼Œé™åˆ¶äº†æ¨¡å‹çš„æ€§èƒ½å’Œæ•ˆç‡ã€‚
  - **çŸ¥è¯†æ··æ‚æ€§ï¼ˆKnowledge Hybridityï¼‰**ï¼šåœ¨ä¼ ç»Ÿçš„ MoE æ¶æ„ä¸­ï¼Œé€šå¸¸åªä½¿ç”¨æœ‰é™æ•°é‡çš„ä¸“å®¶ï¼ˆä¾‹å¦‚ 8 ä¸ªæˆ– 16 ä¸ªï¼‰ã€‚å½“æŸä¸ª token è¢«åˆ†é…ç»™æŸä¸ªä¸“å®¶æ—¶ï¼Œè¿™äº›ä¸“å®¶æ‰€æ¶µç›–çš„çŸ¥è¯†å¾€å¾€æ˜¯å¤šæ ·åŒ–çš„ï¼Œå› æ­¤è¯¥ä¸“å®¶çš„å‚æ•°ä¼šè¯•å›¾åŒæ—¶å­˜å‚¨å’Œå¤„ç†éå¸¸ä¸åŒç±»å‹çš„çŸ¥è¯†ã€‚è¿™ç§çŸ¥è¯†çš„å¤šæ ·æ€§å’Œå¤æ‚æ€§å¯¼è‡´ä¸“å®¶çš„çŸ¥è¯†æ— æ³•é«˜åº¦ä¸“æ³¨å’Œèšç„¦ï¼Œä»è€Œéš¾ä»¥åœ¨åŒä¸€æ¨¡å‹ä¸­æœ‰æ•ˆåœ°åˆ©ç”¨è¿™äº›ä¸åŒç±»å‹çš„çŸ¥è¯†ã€‚
  - **çŸ¥è¯†å†—ä½™æ€§ï¼ˆKnowledge Redundancyï¼‰**ï¼šåœ¨ MoE æ¶æ„ä¸­ï¼Œä¸åŒçš„ä¸“å®¶å¯èƒ½éœ€è¦å…±äº«ç›¸åŒçš„çŸ¥è¯†ã€‚å½“å¤šä¸ªä¸“å®¶è¢«åˆ†é…åˆ°ç±»ä¼¼çš„ä»»åŠ¡æ—¶ï¼Œå®ƒä»¬å¯èƒ½ä¼šé‡å¤å­¦ä¹ å’Œå­˜å‚¨ç›¸åŒçš„çŸ¥è¯†ï¼Œè¿™å¯¼è‡´äº†å¤šä¸ªä¸“å®¶ä¹‹é—´çš„çŸ¥è¯†å†—ä½™ï¼Œæµªè´¹äº†å­˜å‚¨èµ„æºï¼ŒåŒæ—¶ä¹Ÿé™åˆ¶äº†ä¸“å®¶åœ¨å…¶å„è‡ªé¢†åŸŸçš„ä¸“é—¨åŒ–ï¼Œä½¿å…¶æ— æ³•è¾¾åˆ° MoE æ¨¡å‹çš„ç†è®ºä¸Šé™æ€§èƒ½ã€‚

### åŸºæœ¬æ€æƒ³

![37d134bb-b70c-40db-bc79-7e9857fb9364](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/37d134bb-b70c-40db-bc79-7e9857fb9364.webp)

#### **ç²¾ç»†åŒ–ä¸“å®¶åˆ’åˆ†**

> åˆ’åˆ†æ›´ç»†ï¼Œä¸“å®¶æ›´åŠ ä¸“ä¸šåŒ–ï¼ŒåŒæ—¶å¯ä»¥è·¯ç”±åˆ°æ›´å¤šçš„ä¸“å®¶

åœ¨ä¿æŒå‚æ•°æ€»é‡ä¸å˜çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬é€šè¿‡æ‹†åˆ† FFN çš„ä¸­é—´éšè—å±‚ç»´åº¦æ¥å¯¹ä¸“å®¶è¿›è¡Œæ›´åŠ ç²¾ç»†çš„åˆ’åˆ†ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬æ¿€æ´»æ›´å¤šçš„ç²¾ç»†åŒ–ä¸“å®¶ï¼Œä»è€Œå®ç°æ›´çµæ´»ã€æ›´é€‚åº”çš„ä¸“å®¶ç»„åˆã€‚ç²¾ç»†åŒ–çš„ä¸“å®¶åˆ’åˆ†å…è®¸å¤šæ ·åŒ–çš„çŸ¥è¯†æ›´åŠ ç»†è‡´åœ°åˆ†è§£å’Œå­¦ä¹ ï¼Œä»è€Œä½¿æ¯ä¸ªä¸“å®¶èƒ½å¤Ÿä¸“æ³¨äºæ›´é«˜å±‚æ¬¡çš„ä¸“ä¸šåŒ–ä»»åŠ¡ã€‚ä¸“å®¶æ¿€æ´»çš„çµæ´»æ€§å¢åŠ ï¼Œä¹Ÿæœ‰åŠ©äºæ›´å‡†ç¡®å’Œé’ˆå¯¹æ€§åœ°è·å–çŸ¥è¯†ã€‚

![1b164aa0-fc5a-4b89-8cff-69294513d65e](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/1b164aa0-fc5a-4b89-8cff-69294513d65e.webp)

#### **å…±äº«ä¸“å®¶éš”ç¦»**

æˆ‘ä»¬å°†éƒ¨åˆ†ä¸“å®¶éš”ç¦»å‡ºæ¥ï¼Œä½œä¸ºâ€œå…±äº«ä¸“å®¶â€ï¼Œå§‹ç»ˆè¢«æ¿€æ´»ï¼Œç”¨äºæ•æ‰å’Œæ•´åˆä¸åŒä¸Šä¸‹æ–‡ä¸­çš„å…±äº«çŸ¥è¯†ã€‚é€šè¿‡å°†å…±äº«çŸ¥è¯†å‹ç¼©åˆ°è¿™äº›å…±äº«ä¸“å®¶ä¸­ï¼Œå‡å°‘äº†å…¶ä»–ä¸“å®¶ä¹‹é—´çš„å†—ä½™ï¼Œä»è€Œæé«˜äº†å‚æ•°çš„æ•ˆç‡ï¼Œç¡®ä¿æ¯ä¸ªè·¯ç”±ä¸“å®¶èƒ½å¤Ÿä¸“æ³¨äºç‹¬ç‰¹çš„é¢†åŸŸï¼Œä¿æŒé«˜æ°´å¹³çš„ä¸“é—¨åŒ–ã€‚

![3aeff8bc-1d9d-4e03-a101-fd6d34c6b31e](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/3aeff8bc-1d9d-4e03-a101-fd6d34c6b31e.webp)

![2d03bf2c-1142-416b-8921-739967b392e9](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/2d03bf2c-1142-416b-8921-739967b392e9.webp)

#### **è´Ÿè½½å‡è¡¡é—®é¢˜**

é™¤äº†åœ¨æ¨¡å‹æ¶æ„ä¸Šçš„æ”¹è¿›ï¼Œéšç€DeepSeekä»V1 åˆ° V3çš„æ¼”è¿›ï¼Œåœ¨è´Ÿè½½å‡è¡¡ä¸Šï¼Œåšäº†è¾ƒå¤šå·¥ä½œã€‚

> è™½ç„¶ç¨€ç–é—¨æ§èƒ½åœ¨ä¸å¢åŠ è®¡ç®—æˆæœ¬çš„æƒ…å†µä¸‹æ˜¾è‘—æ‰©å±•æ¨¡å‹å‚æ•°ç©ºé—´ï¼Œä½†å…¶æ€§èƒ½é«˜åº¦ä¾èµ–é—¨æ§æœºåˆ¶çš„æœ‰æ•ˆæ€§ã€‚é—¨æ§æœºåˆ¶æ— æ³•æ§åˆ¶å‘ç»™ä¸“å®¶çš„ token çš„æ¦‚ç‡ï¼Œæ‰€ä»¥åœ¨å®é™…æ“ä½œä¸­ï¼Œä¼šå­˜åœ¨ä¸“å®¶é—´å·¥ä½œè´Ÿè½½åˆ†å¸ƒä¸å‡è¡¡çš„æƒ…å†µã€‚
>
> 1. æŸäº›ä¸“å®¶è¢«é¢‘ç¹ä½¿ç”¨ï¼ˆæ¥æ”¶åˆ°äº†å¾ˆå¤š tokenï¼‰è€Œå…¶ä»–ä¸“å®¶å´å¾ˆå°‘è¢«è°ƒç”¨ï¼ˆæ¥æ”¶çš„ token å¯¥å¯¥æ— å‡ ï¼‰ã€‚è¿™ä¸ä»…ä¸ç¬¦åˆ MoE çš„è®¾è®¡åˆè¡·ï¼ˆæœ¯ä¸šæœ‰ä¸“æ”»ï¼‰ï¼Œè¿˜å½±å“è®¡ç®—æ•ˆç‡ï¼ˆä¾‹å¦‚å¼•èµ·åˆ†å¸ƒå¼è®­ç»ƒä¸­å„å¡é€šè®¯æ—¶çš„è´Ÿè½½ä¸å‡ï¼‰ã€‚
> 2. ä¸“å®¶å¹¶è¡Œè®¡ç®—æ—¶è®¡ç®—ç“¶é¢ˆï¼ˆåˆ†åˆ° 16 å¼ å¡ä¸Šï¼ŒèŠ±äº† 16 å¼ å¡çš„è¿è¡Œæ—¶çš„é’±ï¼Œåªæœ‰ä¸€å¼ å¡åœ¨å·¥ä½œï¼‰

è§£å†³æ–¹æ¡ˆï¼š

![ef67d1fe-4a22-4d68-ba99-6c6b94062200](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/ef67d1fe-4a22-4d68-ba99-6c6b94062200.webp)

##### ä¸“å®¶çº§è´Ÿè½½å‡è¡¡

åšè´Ÿè½½å‡è¡¡çš„åŒæ—¶ï¼Œè€ƒè™‘äº†**ä¿æŒè®¡ç®—æŸå¤±çš„æ’å®šï¼Œä¸éšä¸“å®¶æ•°é‡çš„å˜åŒ–è€Œå˜åŒ–**ã€‚

![893fd346-4dfe-4c4a-9fe9-562173ef022f](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/893fd346-4dfe-4c4a-9fe9-562173ef022f.webp)

![24555d94-2d6d-4920-b1df-47016d853dd3](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/24555d94-2d6d-4920-b1df-47016d853dd3.webp)

ç†è§£ï¼š

$f_i$è¡¨ç¤ºå®é™…åˆ†é…çš„tokençš„ç™¾åˆ†æ¯”ï¼Œ$P_i$è¡¨ç¤ºç†è®ºä¸Šåˆ†é…çš„å¹³å‡ï¼Œç„¶åç®—ä¸€ä¸ªå†…ç§¯ï¼Ÿä½¿ä¹‹å°½å¯èƒ½å°

##### è®¾å¤‡çº§è´Ÿè½½å‡è¡¡

å°†ä¸“å®¶åˆ†æˆ D ç»„ $\{\mathcal{E}_1,\mathcal{E}_2,\ldots,\mathcal{E}_D\}$ï¼Œæ¯ç»„ä¸“å®¶æ”¾åœ¨ä¸€ä¸ªè®¾å¤‡ä¸Šï¼Œä¸ºäº†ä¿è¯è®¾å¤‡é—´çš„è®¡ç®—è´Ÿè½½å‡è¡¡ï¼Œ å¼•å…¥è®¾å¤‡çº§è´Ÿè½½lossã€‚è®¾å¤‡çº§è´Ÿè½½loss æ¯”ä¸“å®¶çº§ç²’åº¦æ›´å¤§ï¼Œç›¸å½“äºåœ¨å¤šç»„ä¸“å®¶é—´åšè´Ÿè½½å‡è¡¡ï¼Œä¸»è¦ç”¨æ¥å¹³è¡¡ä¸åŒè®¾å¤‡çš„è®¡ç®—è´Ÿè½½ã€‚å¦‚ä¸‹å›¾å…¬å¼æ‰€ç¤º

![image-20250427020505000](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250427020505000.webp)



## DeepSeek-V2

DeepSeek V2 ç›¸å¯¹äºV1ç‰ˆï¼Œå¯¹MoEæ¨¡å—ä¸»è¦åœ¨è´Ÿè½½å‡è¡¡ä¸Šåšäº†ä¸‰æ–¹é¢å‡çº§:

1. è®¾å¤‡å—é™çš„ä¸“å®¶è·¯ç”±æœºåˆ¶
2. å¢åŠ é€šä¿¡è´Ÿè½½å‡è¡¡loss
3. è®¾å¤‡çº§Tokenä¸¢å¼ƒç­–ç•¥

## DeepSeek-V3(Reasoning model)

![Refer to caption](https://arxiv.org/html/2412.19437v1/x2.png)

é¦–å…ˆåœ¨åŸºæœ¬çš„MoEæ¡†æ¶ä¸Šï¼Œå»¶ç»­äº†ç»†ç²’åº¦ä¸“å®¶ï¼ˆfiner-grained expertsï¼‰å’Œ å…±äº«ä¸“å®¶ï¼ˆShared Expert Isolationï¼‰çš„è®¾è®¡ã€‚åœ¨é—¨æ§ç½‘ç»œå’Œè´Ÿè½½å‡è¡¡æ–¹é¢éƒ½åšäº†äº›æ”¹è¿›ã€‚å…·ä½“å¦‚ä¸‹ï¼š

### é—¨æ§å‡½æ•°

> é¦–å…ˆ V3 çš„æ¨¡å‹è¿œå¤§äº V2ï¼ŒV3 çš„æ¯å±‚ MOE ä¸­æœ‰ 256 ä¸ªè·¯ç”±ä¸“å®¶ï¼Œ8 ä¸ªæ¿€æ´»ä¸“å®¶ã€‚ä½† V2 ä¸­åªæœ‰ 160 ä¸ªè·¯ç”±ä¸“å®¶ï¼Œ6 ä¸ªæ¿€æ´»ä¸“å®¶ï¼Œä»å‚æ•°ä¸Šå°±å¯ä»¥å‘ç° V3 çš„é—¨æ§å‡½æ•°è®¡ç®—é‡è¿œå¤§äº V2ï¼Œå¤§å®¶ä¹Ÿéƒ½æ¸…æ¥šå½“è®¡ç®—ç»´åº¦å˜å¤§æ—¶ SoftMax çš„å‰å‘å’Œåå‘æ˜¯å¾ˆè€—è´¹è®¡ç®—èµ„æºçš„ï¼Œè€Œ Sigmod ç›´æ¥å°†æ•°å€¼æ˜ å°„åˆ°[0ï¼Œ1]ä¹‹é—´ï¼Œç›¸å¯¹æ¥è¯´æ›´åŠ ç®€å•ã€‚å¯èƒ½å®ç°æ•ˆæœä¹Ÿç±»ä¼¼ï¼Œå› æ­¤ä¸ºäº†æ›´åŠ é«˜æ•ˆçš„è®­ç»ƒä»è€Œè¿›è¡Œäº†æ›¿æ¢ã€‚

![image-20250427022302601](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250427022302601.webp)

### æ— auc lossçš„è´Ÿè½½å‡è¡¡

åŠ lossä¼šå½±å“æ¨¡å‹æ€§èƒ½

![image-20250427022250889](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250427022250889.webp)





![image-20250427010014303](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250427010014303.webp)



## æ¨¡å‹è’¸é¦

> ä¹‹å‰çš„é”™è¯¯ç†è§£æ˜¯MOEå¯ä»¥é™ä½è®¡ç®—é‡ï¼ŒåŒæ—¶æ¶ˆè€—ä¸å¤§çš„æ˜¾å­˜ã€‚çº é”™åå‘ç°MOEæ˜¯æœ‰åšæ¨¡å‹è’¸é¦oræ¨¡å‹é‡åŒ–çš„å¿…è¦çš„ã€‚

![image-20250427011017923](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250427011017923.webp)



- å¼€æºçš„è’¸é¦æ¨¡å‹çš„æ–¹æ¡ˆ

ç”¨DeepSeek R1ç”Ÿæˆæ•°æ®ï¼Œæ‹¿æ¥SFTè®­ç»ƒQwenå°æ¨¡å‹



## æºç 

### æ‰‹æ’•MOE

å«è´Ÿè½½å‡è¡¡çš„åˆ†ælog

```python
class Expert(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.GELU(),
            nn.Linear(hidden_dim, output_dim))
    def forward(self, x):
        return self.net(x)
    
class MoE(nn.Module):
    def __init__(self, input_dim, num_experts, top_k, expert_capacity, hidden_dim, output_dim):
        super().__init__()
        self.num_experts = num_experts
        self.top_k = top_k
        self.expert_capacity = expert_capacity
        
        # è·¯ç”±ç½‘ç»œ
        self.gate = nn.Linear(input_dim, num_experts)
        
        # ä¸“å®¶é›†åˆ
        self.experts = nn.ModuleList(
            [Expert(input_dim, hidden_dim, output_dim) for _ in range(num_experts)])
        
    def forward(self, x):
        batch_size, input_dim = x.shape
        device = x.device
        
        # è·¯ç”±è®¡ç®—
        logits = self.gate(x)
        probs = torch.softmax(logits, dim=-1)
        print("probs: ", probs)
        topk_probs, topk_indices = torch.topk(probs, self.top_k, dim=-1)
        print("topk_probs: ", topk_probs)
        print("topk_indices: ", topk_indices)
        # è¾…åŠ©æŸå¤±è®¡ç®—
        if self.training:
            # é‡è¦æ€§æŸå¤±ï¼ˆä¸“å®¶åˆ©ç”¨ç‡å‡è¡¡ï¼‰
            importance = probs.sum(0)
            importance_loss = torch.var(importance) / (self.num_experts ** 2)
            
            # è´Ÿè½½å‡è¡¡æŸå¤±ï¼ˆæ ·æœ¬åˆ†é…å‡è¡¡ï¼‰
            mask = torch.zeros_like(probs, dtype=torch.bool)
            mask.scatter_(1, topk_indices, True)
            routing_probs = probs * mask
            expert_usage = mask.float().mean(0)
            routing_weights = routing_probs.mean(0)
            load_balance_loss = self.num_experts * (expert_usage * routing_weights).sum()
            
            aux_loss = importance_loss + load_balance_loss
        else:
            aux_loss = 0.0
        # ä¸“å®¶åˆ†é…é€»è¾‘
        flat_indices = topk_indices.view(-1)
        flat_probs = topk_probs.view(-1)
        sample_indices = torch.arange(batch_size, device=device)[:, None]\
                            .expand(-1, self.top_k).flatten()
        print("sample_indices: ", sample_indices)
        # åˆå§‹åŒ–è¾“å‡º
        outputs = torch.zeros(batch_size, self.experts[0].net[-1].out_features, 
                            device=device)
        # å¤„ç†æ¯ä¸ªä¸“å®¶
        for expert_idx in range(self.num_experts):
            print("expert_idx: ", expert_idx)
            # è·å–åˆ†é…ç»™å½“å‰ä¸“å®¶çš„æ ·æœ¬
            expert_mask = flat_indices == expert_idx
            print("expert_mask: ", expert_mask)
            expert_samples = sample_indices[expert_mask]
            print("expert_samples: ", expert_samples)
            expert_weights = flat_probs[expert_mask]
            print("expert_weights: ", expert_weights)
            # å®¹é‡æ§åˆ¶
            if len(expert_samples) > self.expert_capacity:
                expert_samples = expert_samples[:self.expert_capacity]
                expert_weights = expert_weights[:self.expert_capacity]
            if len(expert_samples) == 0:
                continue
            # å¤„ç†ä¸“å®¶è®¡ç®—
            expert_input = x[expert_samples]
            print("expert_input: ", expert_input)
            expert_output = self.experts[expert_idx](expert_input)
            weighted_output = expert_output * expert_weights.unsqueeze(-1)
            
            # ç´¯åŠ è¾“å‡º
            outputs.index_add_(0, expert_samples, weighted_output)
        return outputs, aux_loss
# æµ‹è¯•ç¤ºä¾‹
if __name__ == "__main__":
    input_dim = 5
    output_dim = 10
    num_experts = 8
    top_k = 3
    expert_capacity = 32
    hidden_dim = 512
    batch_size = 10
    # add
    device = torch.device("npu:4" if torch.npu.is_available() else "cpu")
    moe = MoE(input_dim, num_experts, top_k, expert_capacity, hidden_dim, output_dim).to(device)
    x = torch.randn(batch_size, input_dim).to(device)
    moe.eval()
    output, _ = moe(x)
    print(f"Eval output shape: {output.shape}") # torch.Size([64, 256])
```



### KD + MOE

```python
# https://github.com/cm2solutions/deepseek-r1-distillation/tree/main
class DeepSeekDistiller:
    """
    Main class for knowledge distillation of DeepSeek R1 models.
    """
    
    def __init__(
        self,
        teacher_model: Union[str, PreTrainedModel],
        student_model: Union[str, PreTrainedModel],
        tokenizer: Optional[Any] = None,
        temperature: float = 2.0,
        alpha: float = 0.5,
        hidden_loss_weight: float = 0.0,
        attention_loss_weight: float = 0.0,
        relation_loss_weight: float = 0.0,
        distill_method: str = "kd",
        device: str = "cuda" if torch.cuda.is_available() else "cpu",
        teacher_dtype: str = "float16",
        student_dtype: str = "float16",
    ):
        """
        Initialize the distiller.
        
        Args:
            teacher_model: Teacher model or path to teacher model
            student_model: Student model or path to student model
            tokenizer: Tokenizer for both models
            temperature: Temperature for distillation
            alpha: Weight for distillation loss vs task loss
            hidden_loss_weight: Weight for hidden state mimicking
            attention_loss_weight: Weight for attention map mimicking
            relation_loss_weight: Weight for relation-based distillation
            distill_method: Distillation technique to use
            device: Device to run models on
            teacher_dtype: Data type for teacher model
            student_dtype: Data type for student model
        """
        self.device = device
        self.teacher_dtype = self._get_dtype(teacher_dtype)
        self.student_dtype = self._get_dtype(student_dtype)
        
        # Load teacher model
        if isinstance(teacher_model, str):
            self.teacher = AutoModelForCausalLM.from_pretrained(
                teacher_model,
                torch_dtype=self.teacher_dtype,
                device_map="auto" if self.device == "cuda" else None,
                output_hidden_states=True,
                output_attentions=attention_loss_weight > 0,
            )
        else:
            self.teacher = teacher_model
            self.teacher.config.output_hidden_states = True
            self.teacher.config.output_attentions = attention_loss_weight > 0
            
        # Ensure teacher is in eval mode and optionally freeze
        self.teacher.eval()
        for param in self.teacher.parameters():
            param.requires_grad = False
            
        # Load student model
        if isinstance(student_model, str):
            self.student = AutoModelForCausalLM.from_pretrained(
                student_model,
                torch_dtype=self.student_dtype,
                device_map="auto" if self.device == "cuda" else None,
                output_hidden_states=True,
                output_attentions=attention_loss_weight > 0,
            )
        else:
            self.student = student_model
            self.student.config.output_hidden_states = True
            self.student.config.output_attentions = attention_loss_weight > 0
            
        # Load tokenizer if not provided
        if tokenizer is None:
            if isinstance(teacher_model, str):
                self.tokenizer = AutoTokenizer.from_pretrained(teacher_model)
            else:
                self.tokenizer = AutoTokenizer.from_pretrained(student_model if isinstance(student_model, str) else "deepseek-ai/deepseek-r1-model-330m")
        else:
            self.tokenizer = tokenizer
            
        # Initialize distillation loss
        self.distillation_loss = DistillationLoss(
            temperature=temperature,
            alpha=alpha,
            hidden_loss_weight=hidden_loss_weight,
            attention_loss_weight=attention_loss_weight,
            relation_loss_weight=relation_loss_weight,
            distill_method=distill_method,
        )
        
    def _get_dtype(self, dtype_str: str) -> torch.dtype:
        """
        Convert string dtype to torch dtype.
        
        Args:
            dtype_str: String representation of dtype
            
        Returns:
            Corresponding torch dtype
        """
        dtype_map = {
            "float32": torch.float32,
            "float16": torch.float16,
            "bfloat16": torch.bfloat16,
        }
        return dtype_map.get(dtype_str, torch.float32)
    
    def train_step(
        self,
        input_ids: torch.Tensor,
        attention_mask: torch.Tensor,
        labels: Optional[torch.Tensor] = None,
    ) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:
        """
        Perform a single training step.
        
        Args:
            input_ids: Input token IDs
            attention_mask: Attention mask
            labels: Optional labels for supervised loss
            
        Returns:
            Total loss and dictionary of component losses
        """
        # Get teacher outputs (no gradients needed)
        with torch.no_grad():
            teacher_outputs = self.teacher(
                input_ids=input_ids,
                attention_mask=attention_mask,
                return_dict=True,
            )
            
        # Get student outputs
        student_outputs = self.student(
            input_ids=input_ids,
            attention_mask=attention_mask,
            labels=labels,  # This will compute loss internally if provided
            return_dict=True,
        )
        
        # Calculate distillation loss
        total_loss, losses = self.distillation_loss(
            student_outputs=student_outputs,
            teacher_outputs=teacher_outputs,
            labels=labels,
            attention_mask=attention_mask,
        )
        
        return total_loss, losses
    
    def save_student(self, output_dir: str):
        """
        Save the student model and tokenizer.
        
        Args:
            output_dir: Directory to save model to
        """
        self.student.save_pretrained(output_dir)
        self.tokenizer.save_pretrained(output_dir)
```











## å‚è€ƒèµ„æ–™

- [MOE ä»‹ç»](https://kevincheung2259.github.io/2024/09/13/MOE-Intro/index.html)

- [DeepSeek æŠ€æœ¯è§£æ](https://deepseek.csdn.net/67fa2941da5d787fd5cb6acb.html)

- [è´Ÿè½½å‡è¡¡éƒ¨åˆ†å‚è€ƒèµ„æ–™](https://www.cnblogs.com/rossiXYZ/p/18835426#0x00-æ¦‚è¿°)

- [å˜m_eçš„å‚è€ƒ](https://zhuanlan.zhihu.com/p/18565423596)

- [Deepseek-v3](https://zhuanlan.zhihu.com/p/14988009150)

  
