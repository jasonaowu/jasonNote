---
article: false
title: 协同过滤
order: 2
---

## 相似度度量方法

### 杰卡德相似系数

对于用户 *u* 和 *v* ，该公式反映了两个交互物品交集的数量占这两个用户交互物品并集的数量的比例。

![image-20250422155011854](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250422155011854.webp)

### 余弦相似度
<<<<<<< HEAD

余弦相似度衡量了两个向量的夹角，夹角越小越相似。

![image-20250422160218059](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250422160218059.webp)

![image-20250422161036015](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250422161036015.webp)

- 为什么Jaccard相似系数难以反映用户的具体**评分喜好信息**？而余弦相似度可以？
  - 由于交互矩阵中的元素为 0 或 1，余弦相似度的计算实际上衡量的是两个用户对物品的交互行为方向的相似性。如果两个用户的交互行为非常相似（即他们有相似的偏好或评分模式），则余弦相似度接近 1；反之，如果他们的行为差异较大，余弦相似度接近 0。
  - **余弦相似度**适用于那些需要考虑评分强度和交互行为数量的场景（如推荐系统中的评分预测）。**杰卡德相似系数**适用于那些关注是否有共同偏好（如物品选择）而不关心评分差异的场景。

### 皮尔逊相关系数

皮尔逊相关系数通过使用用户的平均分对各独立评分进行修正，减小了**用户评分偏置的影响**。(例如有的用户就是给分较高，有的用户就是给分偏低)

![image-20250422160809324](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250422160809324.webp)

### 总结

1. Jaccard相似系数
   1. 表示两个集合的交集元素个数在并集中所占的比例 ，所以适用于**隐式反馈数据**（0-1）。
   2. 一般无法反映具体用户的评分喜好信息，所以常用来评估用户是否会对某物品进行打分， 而不是预估用户会对某物品打多少分。
2. 余弦相似度
   1. 适用于稀疏数据，可以处理不同长度的向量，比较不受向量大小影响。在度量文本相似度、用户相似度、物品相似度的时候都较为常用。
   2. cosine相似度计算简单方便，一般较为常用。但是，当用户的评分数据存在 bias 时，效果往往不那么好。
      - 简而言之，就是不同用户评分的偏向不同。部分用户可能乐于给予好评，而部分用户习惯给予差评或者乱评分。
      - 这个时候，根据cosine 相似度计算出来的推荐结果效果会打折扣。
3. 皮尔逊相关度
   1. 实际上也是一种余弦相似度。不过先对向量做了中心化，范围在 **−1 到 1**
   2. 相关度量的是两个变量的变化趋势是否一致，两个随机变量是不是**同增同减**。
   3. **不适合用作计算布尔值向量**（0-1）之间相关度

## 算法评估

### 召回率

用户真正喜欢的物品被推荐出来的数目 / 用户真正喜欢的物品数目

![image-20250422165519107](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250422165519107.webp)

### 精确率

用户真正喜欢的物品被推荐出来的数目 / 推荐的物品总数

![image-20250422171649231](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250422171649231.webp)

### ROC





### AUC



### GAUC





## UserCF

核心思想：

> 用户 sim 用户 like 商品
>
> 用户与用户的相似度用他们共同喜欢的物品数目来衡量。

User-based算法存在两个重大问题：

1. 数据稀疏性

   - 一个大型的电子商务推荐系统一般有非常多的物品，用户可能买的其中不到1%的物品，不同用户之间买的物品**重叠性较低**，导致算法无法找到一个用户的邻居，即偏好相似的用户。

   - 这导致UserCF不适用于那些正反馈获取较困难的应用场景(如酒店预订， 大件物品购买等低频应用)。

2. 算法扩展性

   - 基于用户的协同过滤需要维护用户相似度矩阵以便快速的找出 TopN 相似用户， 该矩阵的存储开销非常大，存储空间随着用户数量的增加而增加。

   - 故不适合用户数据量大的情况使用。

由于UserCF技术上的两点缺陷， 导致很多电商平台并没有采用这种算法， 而是采用了ItemCF算法实现最初的推荐系统。

> 在新闻推荐系统中，若使用UserCF技术，即使是128G内存，都会爆

## ItemCF

> 用户 like 历史物品 sim 候选物品
>
> 物品的相似度 用 喜欢物品的用户数量来计算

### 用户相似度

用户有共同的 兴趣点

![image-20250306152438377](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250306152438377.webp)

- $I$ 表示两个用户共同喜欢的物品个数
- 是0-1之间的数字

### 改进版ItemCF

改进：公式同等对待热门和冷门的物品

- 现有问题

​	<img src="https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250306152940957.webp" alt="image-20250306152940957" style="zoom:50%;" />

- 解决方案

<img src="https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250306153051180.webp" alt="image-20250306153051180" style="zoom:67%;" />

喜欢物品的用户越多，物品越热门，其权重应该越低

 - 为什么是log?
   - 因为log 更平滑，不会将热门物品的权重视为0

![image-20250422191321592](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250422191321592.webp)

## 适用场景

（1）UserCF

- 由于是基于用户相似度进行推荐， 所以具备更强的社交特性， 这样的特点非常适于**用户少， 物品多， 时效性较强的场合**。

- 比如新闻推荐场景， 因为新闻本身兴趣点分散， 相比用户对不同新闻的兴趣偏好， 新闻的及时性，热点性往往更加重要， 所以正好适用于发现热点，跟踪热点的趋势。

（2）ItemCF

- 这个更适用于兴趣变化较为稳定的应用， 更接近于个性化的推荐， 适合**物品少，用户多，用户兴趣固定持久， 物品更新速度不是太快的场合**。
- 比如推荐艺术品， 音乐， 电影。

## Swing

给用户设置权重，解决小圈子问题

<img src="https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250306140555449.webp" alt="image-20250306140555449" style="zoom:50%;" />

在计算相似度的时候，会把$overlap(u_1,u_2)$放在分母上

 <img src="https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250306141401163.webp" alt="image-20250306141401163" style="zoom:50%;" />

计算相似度的时候，要关于集合$V$中的用户求连加，把用户记作$u_1,u_2$，他们都属于集合$V$，说明用户 $u_1,u_2$ 都对物品 $i_1,i_2$ 感兴趣，这种用户越多就说明物品 $i_1,i_2$ 越相似，

- $\alpha$是超参数，需要调节
- $overlap(u_1,u_2)$是用户 $u_1,u_2$ 的重叠度，重叠度大，说明两人是一个小圈子，对相似度的贡献比较小

<img src="https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250306142113142.webp" alt="image-20250306142113142" style="zoom:50%;" />

## 协同过滤算法的问题

1. 协同过滤算法存在的问题之一就是泛化能力弱：

- 即协同过滤无法将两个物品相似的信息推广到其他物品的相似性上。
- 导致的问题是**热门物品具有很强的头部效应， 容易跟大量物品产生相似， 而尾部物品由于特征向量稀疏， 导致很少被推荐**。

![image-20250422192656715](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250422192656715.webp)

2. 协同过滤的优点就是没有使用更多的用户或者物品属性信息，仅利用用户和物品之间的交互信息就能完成推荐，该算法简单高效。但这也是协同过滤算法的一个弊端。由于**未使用更丰富的用户和物品特征信息**，这也导致协同过滤算法的模型表达能力有限。对于该问题，逻辑回归模型（LR）可以更好地在推荐模型中引入更多特征信息，提高模型的表达能力。

## 矩阵分解

协同过滤算法的特点：

- 协同过滤算法的特点就是**完全没有利用到物品本身或者是用户自身的属性**， 仅仅利用了用户与物品的交互信息就可以实现推荐，是一个可解释性很强， 非常直观的模型。
- 但是也存在一些问题，**处理稀疏矩阵的能力比较弱**。

为了使得协同过滤更好处理稀疏矩阵问题， 增强泛化能力。从协同过滤中衍生出**矩阵分解模型**(Matrix Factorization, MF)或者叫**隐语义模型**：

如果我们知道了用户A和用户B两个用户在豆瓣的读书列表， 从他们的阅读列表可以看出，用户A的兴趣涉及侦探小说、科普图书以及一些计算机技术书， 而用户B的兴趣比较集中在数学和机器学习方面。 那么如何给A和B推荐图书呢？ 先说说协同过滤算法， 这样好对比不同：

- 对于UserCF，首先需要找到和他们看了同样书的其他用户（兴趣相似的用户），然后给他们推荐那些用户喜欢的其他书。
- 对于ItemCF，需要给他们推荐和他们已经看的书相似的书，比如作者B看了很多关于数据挖掘的书，可以给他推荐机器学习或者模式识别方面的书。

而如果是隐语义模型的话，它会先通过一些角度把用户兴趣和这些书归一下类，当来了用户之后，首先得到他的**兴趣分类**， 然后从这个分类中挑选他可能喜欢的书籍。

隐语义模型和协同过滤的不同主要体现在**隐含特征**上，比如书籍的话它的内容，作者，年份，主题等都可以算隐含特征。**有没有感觉到是把协同过滤算法进行了一种延伸， 把用户的相似性和物品的相似性通过了一个叫做隐向量的方式进行表达**

![image-20250422210955210](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250422210955210.webp)

### 算法原理

在矩阵分解的算法框架下， **可以通过分解协同过滤的共现矩阵（评分矩阵）来得到用户和物品的隐向量**，原理如下：

![image-20250422212606068](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250422212606068.webp)
=======

余弦相似度衡量了两个向量的夹角，夹角越小越相似。

![image-20250422160218059](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250422160218059.webp)

![image-20250422161036015](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250422161036015.webp)

- 为什么Jaccard相似系数难以反映用户的具体**评分喜好信息**？而余弦相似度可以？
  - 由于交互矩阵中的元素为 0 或 1，余弦相似度的计算实际上衡量的是两个用户对物品的交互行为方向的相似性。如果两个用户的交互行为非常相似（即他们有相似的偏好或评分模式），则余弦相似度接近 1；反之，如果他们的行为差异较大，余弦相似度接近 0。
  - **余弦相似度**适用于那些需要考虑评分强度和交互行为数量的场景（如推荐系统中的评分预测）。**杰卡德相似系数**适用于那些关注是否有共同偏好（如物品选择）而不关心评分差异的场景。

### 皮尔逊相关系数

皮尔逊相关系数通过使用用户的平均分对各独立评分进行修正，减小了**用户评分偏置的影响**。(例如有的用户就是给分较高，有的用户就是给分偏低)

![image-20250422160809324](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250422160809324.webp)

### 总结

1. Jaccard相似系数
   1. 表示两个集合的交集元素个数在并集中所占的比例 ，所以适用于**隐式反馈数据**（0-1）。
   2. 一般无法反映具体用户的评分喜好信息，所以常用来评估用户是否会对某物品进行打分， 而不是预估用户会对某物品打多少分。
2. 余弦相似度
   1. 适用于稀疏数据，可以处理不同长度的向量，比较不受向量大小影响。在度量文本相似度、用户相似度、物品相似度的时候都较为常用。
   2. cosine相似度计算简单方便，一般较为常用。但是，当用户的评分数据存在 bias 时，效果往往不那么好。
      - 简而言之，就是不同用户评分的偏向不同。部分用户可能乐于给予好评，而部分用户习惯给予差评或者乱评分。
      - 这个时候，根据cosine 相似度计算出来的推荐结果效果会打折扣。
3. 皮尔逊相关度
   1. 实际上也是一种余弦相似度。不过先对向量做了中心化，范围在 **−1 到 1**
   2. 相关度量的是两个变量的变化趋势是否一致，两个随机变量是不是**同增同减**。
   3. **不适合用作计算布尔值向量**（0-1）之间相关度

## 算法评估

### 召回率

用户真正喜欢的物品被推荐出来的数目 / 用户真正喜欢的物品数目

![image-20250422165519107](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250422165519107.webp)

### 精确率

用户真正喜欢的物品被推荐出来的数目 / 推荐的物品总数

![image-20250422171649231](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250422171649231.webp)

### ROC

ROC (Receiver Operating Characteristic) 曲线是评估二分类模型性能的重要工具，在推荐系统中也有广泛应用。

ROC 曲线绘制了不同阈值下的真正例率（TPR，又称召回率）和假正例率（FPR）之间的关系：
- 真正例率 = TP / (TP + FN)：正确推荐的物品数量 / 用户实际喜欢的所有物品数量
- 假正例率 = FP / (FP + TN)：错误推荐的物品数量 / 用户实际不喜欢的所有物品数量

![ROC曲线示例](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250422173015123.webp)

ROC 曲线的特点：
1. 曲线越靠近左上角，表示模型性能越好
2. 对角线代表随机猜测的性能
3. 不受样本不平衡问题的影响，适合推荐系统中正负样本比例失衡的情况

### AUC

AUC (Area Under Curve) 是ROC曲线下的面积，用于量化模型的整体性能。AUC值介于0到1之间，值越大表示模型性能越好。

![AUC示例](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250422174512345.webp)

AUC的物理意义：从所有正样本和负样本对中随机选择一对，模型正确区分它们的概率。

AUC的优势：
1. 对样本类别不平衡不敏感
2. 尺度不变性，不受评分标准影响
3. 提供了对模型整体性能的单一度量

### GAUC

GAUC (Group AUC) 是对AUC的扩展，专门用于评估推荐系统中的个性化推荐效果。

GAUC计算方法：先计算每个用户的AUC，然后根据用户的权重（通常是用户的交互数量）进行加权平均。

![GAUC计算公式](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250422175623456.webp)

GAUC的优势：
1. 更好地反映个性化推荐的效果
2. 考虑了不同用户的重要性
3. 在工业界推荐系统评估中广泛使用





## UserCF

核心思想：

> 用户 sim 用户 like 商品
>
> 用户与用户的相似度用他们共同喜欢的物品数目来衡量。

User-based算法存在两个重大问题：

1. 数据稀疏性

   - 一个大型的电子商务推荐系统一般有非常多的物品，用户可能买的其中不到1%的物品，不同用户之间买的物品**重叠性较低**，导致算法无法找到一个用户的邻居，即偏好相似的用户。

   - 这导致UserCF不适用于那些正反馈获取较困难的应用场景(如酒店预订， 大件物品购买等低频应用)。

2. 算法扩展性

   - 基于用户的协同过滤需要维护用户相似度矩阵以便快速的找出 TopN 相似用户， 该矩阵的存储开销非常大，存储空间随着用户数量的增加而增加。

   - 故不适合用户数据量大的情况使用。

由于UserCF技术上的两点缺陷， 导致很多电商平台并没有采用这种算法， 而是采用了ItemCF算法实现最初的推荐系统。

> 在新闻推荐系统中，若使用UserCF技术，即使是128G内存，都会爆

## ItemCF

> 用户 like 历史物品 sim 候选物品
>
> 物品的相似度 用 喜欢物品的用户数量来计算

### 用户相似度

用户有共同的 兴趣点

![image-20250306152438377](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250306152438377.webp)

- $I$ 表示两个用户共同喜欢的物品个数
- 是0-1之间的数字

### 改进版ItemCF

改进：公式同等对待热门和冷门的物品

- 现有问题

​	<img src="https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250306152940957.webp" alt="image-20250306152940957" style="zoom:50%;" />

- 解决方案

<img src="https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250306153051180.webp" alt="image-20250306153051180" style="zoom:67%;" />

喜欢物品的用户越多，物品越热门，其权重应该越低

 - 为什么是log?
   - 因为log 更平滑，不会将热门物品的权重视为0

![image-20250422191321592](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250422191321592.webp)

## 适用场景

（1）UserCF

- 由于是基于用户相似度进行推荐， 所以具备更强的社交特性， 这样的特点非常适于**用户少， 物品多， 时效性较强的场合**。

- 比如新闻推荐场景， 因为新闻本身兴趣点分散， 相比用户对不同新闻的兴趣偏好， 新闻的及时性，热点性往往更加重要， 所以正好适用于发现热点，跟踪热点的趋势。

（2）ItemCF

- 这个更适用于兴趣变化较为稳定的应用， 更接近于个性化的推荐， 适合**物品少，用户多，用户兴趣固定持久， 物品更新速度不是太快的场合**。
- 比如推荐艺术品， 音乐， 电影。

## Swing

给用户设置权重，解决小圈子问题

<img src="https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250306140555449.webp" alt="image-20250306140555449" style="zoom:50%;" />

在计算相似度的时候，会把$overlap(u_1,u_2)$放在分母上

 <img src="https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250306141401163.webp" alt="image-20250306141401163" style="zoom:50%;" />

计算相似度的时候，要关于集合$V$中的用户求连加，把用户记作$u_1,u_2$，他们都属于集合$V$，说明用户 $u_1,u_2$ 都对物品 $i_1,i_2$ 感兴趣，这种用户越多就说明物品 $i_1,i_2$ 越相似，

- $\alpha$是超参数，需要调节
- $overlap(u_1,u_2)$是用户 $u_1,u_2$ 的重叠度，重叠度大，说明两人是一个小圈子，对相似度的贡献比较小

<img src="https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250306142113142.webp" alt="image-20250306142113142" style="zoom:50%;" />

## 协同过滤算法的问题

1. 协同过滤算法存在的问题之一就是泛化能力弱：

- 即协同过滤无法将两个物品相似的信息推广到其他物品的相似性上。
- 导致的问题是**热门物品具有很强的头部效应， 容易跟大量物品产生相似， 而尾部物品由于特征向量稀疏， 导致很少被推荐**。

![image-20250422192656715](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250422192656715.webp)

2. 协同过滤的优点就是没有使用更多的用户或者物品属性信息，仅利用用户和物品之间的交互信息就能完成推荐，该算法简单高效。但这也是协同过滤算法的一个弊端。由于**未使用更丰富的用户和物品特征信息**，这也导致协同过滤算法的模型表达能力有限。对于该问题，逻辑回归模型（LR）可以更好地在推荐模型中引入更多特征信息，提高模型的表达能力。

## 矩阵分解

协同过滤算法的特点：

- 协同过滤算法的特点就是**完全没有利用到物品本身或者是用户自身的属性**， 仅仅利用了用户与物品的交互信息就可以实现推荐，是一个可解释性很强， 非常直观的模型。
- 但是也存在一些问题，**处理稀疏矩阵的能力比较弱**。

为了使得协同过滤更好处理稀疏矩阵问题， 增强泛化能力。从协同过滤中衍生出**矩阵分解模型**(Matrix Factorization, MF)或者叫**隐语义模型**：

如果我们知道了用户A和用户B两个用户在豆瓣的读书列表， 从他们的阅读列表可以看出，用户A的兴趣涉及侦探小说、科普图书以及一些计算机技术书， 而用户B的兴趣比较集中在数学和机器学习方面。 那么如何给A和B推荐图书呢？ 先说说协同过滤算法， 这样好对比不同：

- 对于UserCF，首先需要找到和他们看了同样书的其他用户（兴趣相似的用户），然后给他们推荐那些用户喜欢的其他书。
- 对于ItemCF，需要给他们推荐和他们已经看的书相似的书，比如作者B看了很多关于数据挖掘的书，可以给他推荐机器学习或者模式识别方面的书。

而如果是隐语义模型的话，它会先通过一些角度把用户兴趣和这些书归一下类，当来了用户之后，首先得到他的**兴趣分类**， 然后从这个分类中挑选他可能喜欢的书籍。

隐语义模型和协同过滤的不同主要体现在**隐含特征**上，比如书籍的话它的内容，作者，年份，主题等都可以算隐含特征。**有没有感觉到是把协同过滤算法进行了一种延伸， 把用户的相似性和物品的相似性通过了一个叫做隐向量的方式进行表达**

![image-20250422210955210](https://blog-1316756713.cos.ap-shanghai.myqcloud.com/bolg/image-20250422210955210.webp)

### 算法原理

在矩阵分解的算法框架下， **可以通过分解协同过滤的共现矩阵（评分矩阵）来得到用户和物品的隐向量**，原理如下：


>>>>>>> 803de95





